{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import sys\n",
    "caffe_root = '../../' \n",
    "sys.path.insert(0, caffe_root + 'python') # 确保已经 make pycaffe 了，也可以直接把路径加到 $PYTHONPATH 里\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a bilinear interpolation kernel\n",
    "# credit @longjon\n",
    "def upsample_filt(size):\n",
    "    factor = (size + 1) // 2 # ‘//’ 确保了结果是整数，和‘/’不一样\n",
    "    if size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:size, :size]\n",
    "    return (1 - abs(og[0] - center) / factor) * \\\n",
    "           (1 - abs(og[1] - center) / factor)\n",
    "\n",
    "# set parameters s.t. deconvolutional layers compute bilinear interpolation\n",
    "# N.B. this is for deconvolution without groups\n",
    "# N.B. 啥意思？：\n",
    "#       Derived from the Latin (and italian) nota bene, meaning note well (take notice).：\n",
    "#       It is used to draw the attention to a certain aspect. \n",
    "def interp_surgery(net, layers):\n",
    "    for l in layers:\n",
    "        m, k, h, w = net.params[l][0].data.shape\n",
    "        if m != k:\n",
    "            print 'input + output channels need to be the same'\n",
    "            raise\n",
    "        if h != w:\n",
    "            print 'filters need to be square'\n",
    "            raise\n",
    "        filt = upsample_filt(h)\n",
    "        # 对 layer l 的 weights 进行设置（设置一个 filter）\n",
    "        net.params[l][0].data[range(m), range(k), :, :] = filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [3, 4]]\n",
      "[[ 0.25  0.25]\n",
      " [ 0.25  0.25]]\n"
     ]
    }
   ],
   "source": [
    "x = [[1, 2], [3, 4]]\n",
    "print x\n",
    "mask = upsample_filt(2)\n",
    "print mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# base net -- follow the editing model parameters example to make\n",
    "# a fully convolutional VGG16 net.\n",
    "# http://nbviewer.ipython.org/github/BVLC/caffe/blob/master/examples/net_surgery.ipynb\n",
    "base_weights = '5stage-vgg.caffemodel'\n",
    "\n",
    "# init\n",
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(0)\n",
    "\n",
    "solver = caffe.SGDSolver('solver.prototxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net: \"train_val.prototxt\"\r\n",
      "test_iter: 0\r\n",
      "test_interval: 1000000\r\n",
      "# lr for fine-tuning should be lower than when starting from scratch\r\n",
      "#debug_info: true\r\n",
      "base_lr: 0.000001\r\n",
      "lr_policy: \"step\"\r\n",
      "gamma: 0.1\r\n",
      "iter_size: 10\r\n",
      "# stepsize should also be lower, as we're closer to being done\r\n",
      "stepsize: 10000\r\n",
      "display: 20\r\n",
      "max_iter: 30001\r\n",
      "momentum: 0.9\r\n",
      "weight_decay: 0.0002\r\n",
      "snapshot: 1000\r\n",
      "snapshot_prefix: \"hed\"\r\n",
      "# uncomment the following to default to CPU mode solving\r\n",
      "# solver_mode: CPU\r\n"
     ]
    }
   ],
   "source": [
    "!cat solver.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['upsample_2', 'upsample_4', 'upsample_8', 'upsample_16']\n"
     ]
    }
   ],
   "source": [
    "# do net surgery to set the deconvolution weights for bilinear interpolation\n",
    "interp_layers = [k for k in solver.net.params.keys() if 'up' in k]\n",
    "interp_surgery(solver.net, interp_layers)\n",
    "\n",
    "print interp_layers\n",
    "interp_surgery?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy base weights for fine-tuning\n",
    "# solver.restore('dsn-full-res-3-scales_iter_29000.solverstate')\n",
    "solver.net.copy_from(base_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# solve straight through -- a better approach is to define a solving loop to\n",
    "# 1. take SGD steps\n",
    "# 2. score the model by the test net `solver.test_nets[0]`\n",
    "# 3. repeat until satisfied\n",
    "# solver.step(100000)\n",
    "\n",
    "# step?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**solver.step?**\n",
    "\n",
    "```\n",
    "Docstring:\n",
    "step( (Solver)arg1, (int)arg2) -> None :\n",
    "\n",
    "    C++ signature :\n",
    "        void step(caffe::Solver<float> {lvalue},int)\n",
    "Type:      instancemethod\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面最后一句，会跑很久。一路生成很多 model 文件和 solvestate 文件，比如\n",
    "`hed_iter_41000.caffemodel`, `hed_iter_41000.solverstate`。过程会很慢。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
